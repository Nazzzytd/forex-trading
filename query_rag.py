import os
import sys
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.schema import Document
from dotenv import load_dotenv
import logging
from typing import List, Dict, Any

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- é…ç½® ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PERSIST_DIR = os.path.join(BASE_DIR, "chroma_db")

class ForexRAGQuerySystem:
    def __init__(self, persist_directory: str = "./chroma_db"):
        self.persist_directory = persist_directory
        self.vectorstore = None
        self.embeddings = None
        self.llm = None
        self.retriever = None
        
    def initialize_system(self) -> bool:
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        try:
            # æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.persist_directory):
                logger.error(f"å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {self.persist_directory}")
                return False
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ä½¿ç”¨è‡ªå®šä¹‰åŸºç¡€URL
            api_key = os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("OPENAI_BASE_URL")
            
            if base_url:
                os.environ["OPENAI_API_BASE"] = base_url
            
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            self.embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=api_key
            )
            
            # åŠ è½½å‘é‡æ•°æ®åº“ - ä½¿ç”¨å…¼å®¹æ–¹å¼
            try:
                # å°è¯•æ–°ç‰ˆæœ¬å¯¼å…¥
                from langchain_chroma import Chroma
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
            except ImportError:
                # å›é€€åˆ°æ—§ç‰ˆæœ¬
                from langchain_community.vectorstores import Chroma
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
            
            # åˆ›å»ºæ£€ç´¢å™¨
            self.retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 5}
            )
            
            # åˆå§‹åŒ–LLM - ç§»é™¤ä¸æ”¯æŒçš„å‚æ•°
            self.llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                temperature=0.1,
                # ç§»é™¤ max_tokens å‚æ•°ï¼Œå› ä¸ºæ‚¨çš„APIç«¯ç‚¹ä¸æ”¯æŒ
                openai_api_key=api_key,
                openai_api_base=base_url
            )
            
            logger.info("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def get_relevant_documents(self, question: str) -> List[Document]:
        """è·å–ç›¸å…³æ–‡æ¡£ - ä½¿ç”¨å…¼å®¹çš„æ–¹æ³•"""
        try:
            # å°è¯•ä½¿ç”¨æ–°æ–¹æ³•
            if hasattr(self.retriever, 'invoke'):
                docs = self.retriever.invoke(question)
            else:
                # å›é€€åˆ°æ—§æ–¹æ³•
                docs = self.retriever.get_relevant_documents(question)
            return docs
        except Exception as e:
            logger.error(f"æ£€ç´¢æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
            return []
    
    def format_context(self, docs: List[Document]) -> str:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not docs:
            return "æš‚æ— ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
        
        context_parts = []
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get('source_file', 'æœªçŸ¥æ–‡æ¡£')
            page = doc.metadata.get('page', 0)
            content = doc.page_content.strip()
            
            context_parts.append(f"[æ–‡æ¡£{i}] æ¥æº: {source} (ç¬¬{int(page)+1}é¡µ)\nå†…å®¹: {content}")
        
        return "\n\n".join(context_parts)
    
    def build_enhanced_prompt(self, question: str, context: str) -> str:
        """æ„å»ºå¢å¼ºçš„æç¤ºè¯"""
        return f"""æ‚¨æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–æ±‡äº¤æ˜“åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æä¾›çš„äº¤æ˜“çŸ¥è¯†ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å›ç­”ï¼š
1. ä¸¥æ ¼åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜
2. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜å“ªäº›æ–¹é¢ä¿¡æ¯ä¸è¶³
3. å¯¹äºäº¤æ˜“æŠ€æœ¯åˆ†æï¼Œè¯·è¯¦ç»†è¯´æ˜å½¢æ€ç‰¹å¾å’Œå¸‚åœºæ„ä¹‰
4. å›ç­”è¦ä¸“ä¸šã€å‡†ç¡®ã€å®ç”¨

é—®é¢˜ï¼š{question}

è¯·ç»™å‡ºä¸“ä¸šã€è¯¦ç»†çš„å›ç­”ï¼š"""

    def ask_question(self, question: str) -> Dict[str, Any]:
        """æé—®å¹¶è·å–ç­”æ¡ˆ"""
        try:
            logger.info(f"å¤„ç†é—®é¢˜: {question}")
            
            # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.get_relevant_documents(question)
            context = self.format_context(docs)
            
            # 2. æ„å»ºå¢å¼ºçš„Prompt
            prompt = self.build_enhanced_prompt(question, context)
            
            # 3. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
            response = self.llm.invoke(prompt)
            
            # 4. æ•´ç†ç»“æœ
            result = {
                "question": question,
                "answer": response.content,
                "source_documents": docs,
                "context_used": context
            }
            
            logger.info("é—®é¢˜å¤„ç†å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
            return {
                "question": question,
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "source_documents": [],
                "context_used": ""
            }
    
    def format_response(self, result: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å“åº”ç»“æœ"""
        response = f"ğŸ¤– é—®é¢˜: {result['question']}\n\n"
        response += f"ğŸ’¡ å›ç­”:\n{result['answer']}\n\n"
        
        if result['source_documents']:
            response += "ğŸ“š å‚è€ƒæ¥æº:\n"
            for i, doc in enumerate(result['source_documents'][:3], 1):
                source = doc.metadata.get('source_file', 'æœªçŸ¥æ–‡æ¡£')
                page = doc.metadata.get('page', 0)
                content_preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
                
                response += f"{i}. {source} (ç¬¬{int(page)+1}é¡µ)\n"
                response += f"   ç‰‡æ®µ: {content_preview}\n\n"
        
        return response

def interactive_mode(query_system: ForexRAGQuerySystem):
    """äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼"""
    print("\n" + "=" * 60)
    print("           å¤–æ±‡äº¤æ˜“RAGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("=" * 60)
    print("ğŸ’¡ æ‚¨å¯ä»¥è¯¢é—®å…³äºï¼š")
    print("   â€¢ èœ¡çƒ›å›¾æŠ€æœ¯ï¼ˆé”¤å­çº¿ã€åæ²¡å½¢æ€ç­‰ï¼‰")
    print("   â€¢ æŠ€æœ¯åˆ†ææŒ‡æ ‡")
    print("   â€¢ äº¤æ˜“ç­–ç•¥")
    print("   â€¢ é£é™©ç®¡ç†")
    print("è¾“å…¥ 'quit' æˆ– 'é€€å‡º' ç»“æŸç¨‹åº")
    print("-" * 60)
    
    while True:
        try:
            question = input("\nğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
            
            if question.lower() in ['quit', 'é€€å‡º', 'exit', 'q']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break
                
            if not question:
                continue
                
            # æ‰§è¡ŒæŸ¥è¯¢
            result = query_system.ask_question(question)
            response = query_system.format_response(result)
            print(f"\n{response}")
            print("-" * 60)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–æŸ¥è¯¢ç³»ç»Ÿ
    query_system = ForexRAGQuerySystem()
    
    if not query_system.initialize_system():
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("   1. æ˜¯å¦å·²è¿è¡Œ build_rag.py æ„å»ºçŸ¥è¯†åº“")
        print("   2. OPENAI_API_KEY ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®")
        print("   3. å‘é‡æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨")
        sys.exit(1)
    
    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ¨¡å¼
    if len(sys.argv) > 1:
        # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
        question = " ".join(sys.argv[1:])
        result = query_system.ask_question(question)
        response = query_system.format_response(result)
        print(response)
    else:
        # äº¤äº’å¼æ¨¡å¼
        interactive_mode(query_system)

if __name__ == "__main__":
    main()