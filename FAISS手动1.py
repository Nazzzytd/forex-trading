import numpy as np
import faiss
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
import os

# è®¾ç½®OpenAI APIå¯†é’¥ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å¯†é’¥ï¼‰
api_key=os.environ.get("OPENAI_API_KEY")
base_url=os.environ.get("OPENAI_BASE_URL")
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
class ManualFAISSExperiment:
    def __init__(self):
        self.index=None
        self.embedder=OpenAIEmbeddings()
        self.dimention=1536
        self.memories=[]
        
    def setup_index(self):
        """åˆ›å»ºFAISSç´¢å¼•"""
        self.index=faiss.IndexFlatL2(self.dimention)
        return self.index

    def understand_embeddings(self):
        """ç†è§£åµŒå…¥å‘é‡"""
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "ä¸Šå¸‚å…¬å¸å¹´æŠ¥åˆ†æ",
            "è´¢åŠ¡æŠ¥è¡¨å®¡è®¡",
            "å…¬å¸æ²»ç†ç»“æ„"
        ]
        
        for i, text in enumerate(test_texts):
            embedding = self.embedder.embed_query(text)
            print(f"\næ–‡æœ¬ {i+1}: '{text}'")
            print(f"åµŒå…¥å‘é‡ç»´åº¦: {len(embedding)}")
            print(f"å‰5ä¸ªç»´åº¦å€¼: {embedding[:5]}")
            print(f"å‘é‡èŒƒæ•°: {np.linalg.norm(embedding):.4f}")
        
        return test_texts
    
    def add_vectors_manually(self,texts):
        """æ‰‹åŠ¨æ·»åŠ å‘é‡åˆ°ç´¢å¼•"""
        embedding_list=[]
        
        for i,text in enumerate(texts):
            embedding=self.embedder.embed_query(text)
            embedding_list.append(embedding)

        #self.memories.append({i,text,embedding})é”™è¯¯
            self.memories.append({
                "id":i,
                "text":text,
                "embedding":embedding
            })

        # æ‰¹é‡æ·»åŠ åˆ°FAISSç´¢å¼•ï¼ˆæ³¨æ„æ•°æ®ç±»å‹è½¬æ¢ï¼‰
        embeddings_array=np.array(embedding_list,dtype=np.float32)
        self.index.add(embeddings_array)

        return embeddings_array
    
    def search_manually(self, query_text, k=2):
        """æ‰‹åŠ¨æœç´¢"""
        
        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        query_embed=self.embedder.embed_query(query_text)
        query_array=np.array([query_embed],dtype=np.float32)

        # æ‰§è¡Œæœç´¢
        distances,indices=self.index.search(query_array,k=k)
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        print(f"æœç´¢ç»“æœç´¢å¼•: {indices}")
        print(f"ç›¸ä¼¼åº¦è·ç¦»: {distances}")
        for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):
            if idx != -1:  # æœ‰æ•ˆçš„ç´¢å¼•
                memory = self.memories[idx]
                print(f"{i+1}. ç›¸ä¼¼åº¦: {distance:.4f}")
                print(f"   æ–‡æœ¬: {memory['text']}")
                print(f"   ç´¢å¼•ID: {memory['id']}")
            else:
                print(f"{i+1}. æ— ç»“æœ")
        
        return indices, distances
    
    def run_complete_experiment(self):
        """è¿è¡Œå®Œæ•´çš„æ‰‹åŠ¨FAISSå®éªŒ"""
        print("ğŸš€ å¼€å§‹æ‰‹åŠ¨FAISSå®éªŒ")
        print("=" * 50)
        
        # 1. è®¾ç½®ç´¢å¼•
        self.setup_index()
        
        # 2. ç†è§£åµŒå…¥
        test_texts = self.understand_embeddings()
        
        # 3. æ·»åŠ å‘é‡
        self.add_vectors_manually(test_texts)
        
        # 4. æµ‹è¯•æœç´¢
        test_queries = ["å…¬å¸å¹´æŠ¥", "è´¢åŠ¡åˆ†æ", "æ²»ç†"]
        for query in test_queries:
            self.search_manually(query)
        
        print("\n" + "=" * 50)
        print("âœ… æ‰‹åŠ¨FAISSå®éªŒå®Œæˆï¼")

# è¿è¡Œæ‰‹åŠ¨FAISSå®éªŒ
print("ğŸ¯ å®éªŒ1: æ‰‹åŠ¨FAISSå®ç°")
manual_experiment = ManualFAISSExperiment()
manual_experiment.run_complete_experiment()