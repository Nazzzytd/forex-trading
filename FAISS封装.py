import numpy as np
import faiss
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
import os

# è®¾ç½®OpenAI APIå¯†é’¥ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å¯†é’¥ï¼‰
api_key=os.environ.get("OPENAI_API_KEY")
base_url=os.environ.get("OPENAI_BASE_URL")
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

class LangChainFAISSExperiment:
    def __init__(self):
        self.embedder = OpenAIEmbeddings()
        self.vectorstore = None
    
    def create_documents_with_metadata(self):
        """åˆ›å»ºå¸¦å…ƒæ•°æ®çš„æ–‡æ¡£"""
        print("=== æ­¥éª¤1: åˆ›å»ºæ–‡æ¡£å¯¹è±¡ ===")
        
        # æ¨¡æ‹Ÿä¸Šå¸‚å…¬å¸å¹´æŠ¥å†…å®¹
        annual_report_data = [
            {
                "content": "å…¬å¸2023å¹´å®ç°è¥ä¸šæ”¶å…¥500äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿15%",
                "metadata": {"year": 2023, "section": "è´¢åŠ¡æ‘˜è¦", "page": 1}
            },
            {
                "content": "å‡€åˆ©æ¶¦è¾¾åˆ°60äº¿å…ƒï¼Œå‡€èµ„äº§æ”¶ç›Šç‡ROEä¸º12%", 
                "metadata": {"year": 2023, "section": "ç›ˆåˆ©èƒ½åŠ›", "page": 2}
            },
            {
                "content": "ç ”å‘æŠ•å…¥25äº¿å…ƒï¼Œå è¥ä¸šæ”¶å…¥æ¯”ä¾‹5%",
                "metadata": {"year": 2023, "section": "ç ”å‘æŠ•å…¥", "page": 3}
            },
            {
                "content": "å…¬å¸ç°é‡‘åŠç­‰ä»·ç‰©ä½™é¢ä¸º80äº¿å…ƒï¼Œèµ„äº§è´Ÿå€ºç‡45%",
                "metadata": {"year": 2023, "section": "è´¢åŠ¡çŠ¶å†µ", "page": 4}
            }
        ]
        
        documents = []
        for data in annual_report_data:
            doc = Document(
                page_content=data["content"],
                metadata=data["metadata"]
            )
            documents.append(doc)
            print(f"ğŸ“„ åˆ›å»ºæ–‡æ¡£: {data['content'][:30]}...")
            print(f"   å…ƒæ•°æ®: {data['metadata']}")
        
        return documents
    
    def create_vectorstore(self, documents):
        """åˆ›å»ºFAISSå‘é‡åº“"""
        print("\n=== æ­¥éª¤2: åˆ›å»ºFAISSå‘é‡åº“ ===")
        
        self.vectorstore = FAISS.from_documents(documents, self.embedder)
        
        print("âœ… FAISSå‘é‡åº“åˆ›å»ºæˆåŠŸ")
        print(f"ç´¢å¼•ä¸­çš„æ–‡æ¡£æ•°é‡: {self.vectorstore.index.ntotal}")
        print(f"å‘é‡ç»´åº¦: {self.vectorstore.index.d}")
        
        return self.vectorstore
    
    def demonstrate_search_capabilities(self):
        """æ¼”ç¤ºæœç´¢èƒ½åŠ›"""
        print("\n=== æ­¥éª¤3: æœç´¢åŠŸèƒ½æ¼”ç¤º ===")
        
        test_queries = [
            "è¥ä¸šæ”¶å…¥æƒ…å†µ",
            "ç ”å‘æŠ•å…¥å¤šå°‘",
            "å…¬å¸è´¢åŠ¡çŠ¶å†µ"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
            
            # åŸºç¡€ç›¸ä¼¼åº¦æœç´¢
            results = self.vectorstore.similarity_search(query, k=2)
            print(f"ç›¸ä¼¼åº¦æœç´¢ç»“æœ ({len(results)} ä¸ª):")
            for i, doc in enumerate(results):
                print(f"  {i+1}. {doc.page_content}")
                print(f"     å…ƒæ•°æ®: {doc.metadata}")
            
            # å¸¦åˆ†æ•°çš„æœç´¢
            print(f"\nå¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æœç´¢:")
            results_with_score = self.vectorstore.similarity_search_with_score(query, k=2)
            for i, (doc, score) in enumerate(results_with_score):
                print(f"  {i+1}. åˆ†æ•°: {score:.4f} - {doc.page_content}")
    
    def demonstrate_advanced_features(self):
        """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
        print("\n=== æ­¥éª¤4: é«˜çº§åŠŸèƒ½æ¼”ç¤º ===")
        
        # 1. ä½œä¸ºæ£€ç´¢å™¨ä½¿ç”¨
        print("1. æ£€ç´¢å™¨æ¨¡å¼:")
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}
        )
        results = retriever.invoke("å…¬å¸åˆ©æ¶¦")
        print(f"æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        # 2. ä¿å­˜å’ŒåŠ è½½
        print("\n2. æŒä¹…åŒ–åŠŸèƒ½:")
        save_path = "./faiss_demo_index"
        self.vectorstore.save_local(save_path)
        print(f"âœ… å‘é‡åº“å·²ä¿å­˜åˆ°: {save_path}")
        
        # æ¨¡æ‹ŸåŠ è½½
        try:
            loaded_vectorstore = FAISS.load_local(save_path, self.embedder)
            print(f"âœ… å‘é‡åº“åŠ è½½æˆåŠŸï¼Œæ–‡æ¡£æ•°: {loaded_vectorstore.index.ntotal}")
        except Exception as e:
            print(f"åŠ è½½æ¼”ç¤º: {e}")
    
    def run_complete_experiment(self):
        """è¿è¡Œå®Œæ•´çš„LangChain FAISSå®éªŒ"""
        print("ğŸš€ å¼€å§‹LangChain FAISSå®éªŒ") 
        print("=" * 50)
        
        # 1. åˆ›å»ºæ–‡æ¡£
        documents = self.create_documents_with_metadata()
        
        # 2. åˆ›å»ºå‘é‡åº“
        self.create_vectorstore(documents)
        
        # 3. æœç´¢æ¼”ç¤º
        self.demonstrate_search_capabilities()
        
        # 4. é«˜çº§åŠŸèƒ½
        self.demonstrate_advanced_features()
        
        print("\n" + "=" * 50)
        print("âœ… LangChain FAISSå®éªŒå®Œæˆï¼")

# è¿è¡ŒLangChain FAISSå®éªŒ
print("\nğŸ¯ å®éªŒ2: LangChain FAISSå°è£…")
lc_experiment = LangChainFAISSExperiment()
lc_experiment.run_complete_experiment()