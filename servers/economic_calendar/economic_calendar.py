# economic_calendar.py
import requests
import json
import openai
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

try:
    from ultrarag.core.config_loader import ConfigLoader
except ImportError:
    from ...core.config_loader import ConfigLoader

class EconomicCalendar:
    """
    UltraRAG ç»æµæ—¥å†å·¥å…· - ä½¿ç”¨Alpha Vantageè·å–å¤–æ±‡æ–°é—»å’Œé‡è¦ç»æµæ•°æ®å‘å¸ƒä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨OpenAIè¿›è¡Œåˆ†æ
    """

    def __init__(self, config: Dict = None):
        if config is None:
            # è‡ªåŠ¨åŠ è½½é…ç½®
            try:
                loader = ConfigLoader()
                config_path = os.path.join(os.path.dirname(__file__), "economic_calendar_parameter.yaml")
                config = loader.load_config(config_path)
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                config = {}
        
        # ç»Ÿä¸€ä½¿ç”¨ alpha_api_key
        self.alpha_vantage_key = config.get("alpha_api_key")
        
        # å¦‚æœé…ç½®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œç›´æ¥ä»ç¯å¢ƒå˜é‡è·å–
        if not self.alpha_vantage_key or self.alpha_vantage_key.startswith("${"):
            self.alpha_vantage_key = os.getenv("ALPHA_VANTAGE_API_KEY")
            print("ğŸ”§ ä»ç¯å¢ƒå˜é‡ç›´æ¥è·å– Alpha Vantage API å¯†é’¥")
        
        self.openai_api_key = config.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        self.openai_base_url = config.get("openai_base_url") or os.getenv("OPENAI_BASE_URL")
        
        print(f"ğŸ”§ æœ€ç»ˆé…ç½®:")
        print(f"   Alpha Vantage Key: {'âœ… å·²è®¾ç½®' if self.alpha_vantage_key else 'âŒ æœªè®¾ç½®'}")
        print(f"   OpenAI Key: {'âœ… å·²è®¾ç½®' if self.openai_api_key else 'âŒ æœªè®¾ç½®'}")
        
        # æµ‹è¯•æ¨¡å¼æ£€æµ‹
        self.test_mode = (self.alpha_vantage_key == "TEST_MODE" or 
                         not self.alpha_vantage_key or 
                         self.alpha_vantage_key.startswith("${"))
        
        if self.test_mode:
            print("ğŸ”§ è¿è¡Œåœ¨æµ‹è¯•æ¨¡å¼ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        # APIä½¿ç”¨ç»Ÿè®¡å’Œé™åˆ¶
        self.api_call_count = 0
        self.last_api_call_time = None
        self.daily_limit = 25  # Alpha Vantage å…è´¹ç‰ˆé™åˆ¶
        
        # ç¼“å­˜æœºåˆ¶
        self.news_cache = {}
        self.events_cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
        
        # é…ç½®OpenAIå®¢æˆ·ç«¯
        if self.openai_api_key and not self.openai_api_key.startswith("${"):
            try:
                self.openai_client = openai.OpenAI(
                    api_key=self.openai_api_key,
                    base_url=self.openai_base_url
                )
                print("âœ… EconomicCalendar OpenAIåŠŸèƒ½å·²å¯ç”¨")
            except Exception as e:
                print(f"âŒ EconomicCalendar OpenAIåˆå§‹åŒ–å¤±è´¥: {e}")
                self.openai_client = None
        else:
            print("âš ï¸ EconomicCalendar OpenAIåŠŸèƒ½ä¸å¯ç”¨ - è¯·æ£€æŸ¥ OPENAI_API_KEY é…ç½®")
            self.openai_client = None
        
        # Alpha Vantageç›¸å…³é…ç½®
        self.alpha_vantage_base_url = "https://www.alphavantage.co/query"
        
        # å¤–æ±‡ç›¸å…³ä¸»é¢˜
        self.forex_topics = "economy_monetary,financial_markets"
        
        # è´§å¸å¯¹åˆ°è‚¡ç¥¨ä»£ç çš„æ˜ å°„ï¼ˆç”¨äºæ–°é—»è¿‡æ»¤ï¼‰
        self.currency_to_tickers = {
            'EUR/USD': ['EURUSD', 'EUR', 'USD'],
            'GBP/USD': ['GBPUSD', 'GBP', 'USD'],
            'USD/JPY': ['USDJPY', 'USD', 'JPY'],
            'USD/CHF': ['USDCHF', 'USD', 'CHF'],
            'AUD/USD': ['AUDUSD', 'AUD', 'USD'],
            'USD/CAD': ['USDCAD', 'USD', 'CAD'],
            'NZD/USD': ['NZDUSD', 'NZD', 'USD'],
            'EUR/GBP': ['EURGBP', 'EUR', 'GBP'],
            'EUR/JPY': ['EURJPY', 'EUR', 'JPY']
        }

        # é‡è¦ç»æµæ•°æ®å‘å¸ƒäº‹ä»¶
        self.economic_events = {
            'us': [
                {
                    'name': 'Nonfarm Payrolls',
                    'frequency': 'monthly',
                    'importance': 'high',
                    'source': 'BLS',
                    'typical_time': '08:30 EST',
                    'currency_impact': ['USD', 'EUR/USD', 'GBP/USD', 'USD/JPY'],
                    'typical_day': 1,
                    'av_ticker': 'NFP'
                },
                {
                    'name': 'CPI Inflation',
                    'frequency': 'monthly', 
                    'importance': 'high',
                    'source': 'BLS',
                    'typical_time': '08:30 EST',
                    'currency_impact': ['USD', 'EUR/USD', 'USD/JPY'],
                    'typical_day': 12,
                    'av_ticker': 'CPI'
                },
                {
                    'name': 'Federal Funds Rate',
                    'frequency': '8_times_year',
                    'importance': 'high',
                    'source': 'Federal Reserve',
                    'typical_time': '14:00 EST',
                    'currency_impact': ['USD', 'All majors'],
                    'typical_day': 15,
                    'av_ticker': 'FED'
                },
                {
                    'name': 'GDP Growth Rate',
                    'frequency': 'quarterly',
                    'importance': 'high',
                    'source': 'BEA',
                    'typical_time': '08:30 EST',
                    'currency_impact': ['USD', 'EUR/USD', 'USD/JPY'],
                    'typical_day': 25,
                    'av_ticker': 'GDP'
                }
            ],
            'eu': [
                {
                    'name': 'ECB Interest Rate',
                    'frequency': '8_times_year',
                    'importance': 'high',
                    'source': 'ECB',
                    'typical_time': '12:45 GMT',
                    'currency_impact': ['EUR', 'EUR/USD', 'EUR/GBP'],
                    'typical_day': 10,
                    'av_ticker': 'ECB'
                }
            ],
            'uk': [
                {
                    'name': 'Bank of England Rate',
                    'frequency': '8_times_year',
                    'importance': 'high',
                    'source': 'BOE',
                    'typical_time': '12:00 GMT',
                    'currency_impact': ['GBP', 'GBP/USD', 'EUR/GBP'],
                    'typical_day': 5,
                    'av_ticker': 'BOE'
                }
            ],
            'jp': [
                {
                    'name': 'Bank of Japan Rate',
                    'frequency': '8_times_year',
                    'importance': 'high',
                    'source': 'BOJ',
                    'typical_time': 'æ—¶é—´ varies',
                    'currency_impact': ['JPY', 'USD/JPY', 'EUR/JPY'],
                    'typical_day': 20,
                    'av_ticker': 'BOJ'
                }
            ]
        }

        # å¤–æ±‡äº¤æ˜“ç›¸å…³äº‹ä»¶å…³é”®è¯æ˜ å°„
        self.event_keywords = {
            'central_bank_decision': [
                'interest rate decision', 'federal reserve', 'fed meeting', 'ecb decision',
                'bank of england', 'boe meeting', 'bank of japan', 'boj meeting',
                'monetary policy', 'central bank', 'rate hike', 'rate cut', 'fomc'
            ],
            'inflation_data': [
                'cpi', 'consumer price index', 'inflation data', 'core cpi',
                'pce price index', 'inflation report', 'price pressure', 'inflation rate'
            ],
            'employment_data': [
                'nonfarm payrolls', 'nfp', 'unemployment rate', 'jobless claims',
                'employment change', 'adp employment', 'wage growth', 'jobs report',
                'employment report'
            ],
            'gdp_growth': [
                'gdp growth', 'gross domestic product', 'economic growth',
                'preliminary gdp', 'final gdp', 'recession', 'expansion', 'gdp report'
            ]
        }

        print(f"âœ… Economic Calendar åˆå§‹åŒ–å®Œæˆ")
        print(f"   Alpha Vantage: {'âœ… å¯ç”¨' if self.alpha_vantage_key and not self.test_mode else 'âŒ ç¦ç”¨/æµ‹è¯•æ¨¡å¼'}")
        print(f"   OpenAIåˆ†æ: {'âœ… å¯ç”¨' if self.openai_client else 'âŒ ç¦ç”¨'}")
        print(f"   æ¯æ—¥APIé™åˆ¶: {self.daily_limit} æ¬¡è°ƒç”¨")
        print(f"   ç¼“å­˜TTL: {self.cache_ttl} ç§’")

    def get_news_sentiment(self, topics: str = None, tickers: str = None, limit: int = 50) -> Dict:
        """
        ä½¿ç”¨Alpha Vantageè·å–å¸‚åœºæ–°é—»å’Œæƒ…ç»ªæ•°æ®
        """
        if not self.alpha_vantage_key:
            return {
                "success": False,
                "error": "Alpha Vantage APIå¯†é’¥æœªé…ç½®",
                "source": "economic_calendar"
            }
        
        # æµ‹è¯•æ¨¡å¼ç›´æ¥è¿”å›æ¨¡æ‹Ÿæ•°æ®
        if self.test_mode:
            print("ğŸ”§ æµ‹è¯•æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿæ–°é—»æ•°æ®")
            return self._get_simulated_news()
        
        # æ£€æŸ¥APIé™åˆ¶
        if self._is_api_limit_reached():
            print("âš ï¸ APIè°ƒç”¨é™åˆ¶å·²åˆ°è¾¾ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return self._get_simulated_news()
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"news_{topics}_{tickers}_{limit}"
        if cache_key in self.news_cache:
            cache_time, cached_data = self.news_cache[cache_key]
            if (datetime.now() - cache_time).seconds < self.cache_ttl:
                print("ğŸ” ä½¿ç”¨ç¼“å­˜çš„æ–°é—»æ•°æ®")
                cached_data["source"] = "cached_data"
                return cached_data
        
        try:
            params = {
                'function': 'NEWS_SENTIMENT',
                'apikey': self.alpha_vantage_key,
                'sort': 'LATEST',
                'limit': min(limit, 50)
            }
            
            if topics:
                # æ”¯æŒå¤šä¸ª topics ç”¨é€—å·åˆ†éš”
                topic_list = [t.strip() for t in topics.split(',')]
                valid_topics = []
                
                valid_alpha_topics = [
                    'blockchain', 'earnings', 'ipo', 'mergers_and_acquisitions', 
                    'financial_markets', 'economy_fiscal', 'economy_monetary', 
                    'economy_macro', 'energy_transportation', 'finance', 
                    'life_sciences', 'manufacturing', 'real_estate', 'retail_wholesale', 
                    'technology'
                ]
                
                for topic in topic_list:
                    if topic in valid_alpha_topics:
                        valid_topics.append(topic)
                
                if valid_topics:
                    params['topics'] = ",".join(valid_topics[:2])  # Alpha Vantage é™åˆ¶æœ€å¤š2ä¸ªtopics
            
            if tickers:
                params['tickers'] = tickers
            
            print(f"ğŸ” å‘é€æ–°é—»APIè¯·æ±‚å‚æ•°: {params}")
            
            # è®°å½•APIè°ƒç”¨
            self.api_call_count += 1
            self.last_api_call_time = datetime.now()
            print(f"ğŸ“Š APIè°ƒç”¨ç»Ÿè®¡: {self.api_call_count}/{self.daily_limit}")
            
            response = requests.get(self.alpha_vantage_base_url, params=params, timeout=15)
            response.raise_for_status()
            
            data = response.json()
            
            # æ£€æŸ¥APIé™åˆ¶ä¿¡æ¯
            if 'Information' in data:
                print(f"â„¹ï¸ APIä¿¡æ¯: {data['Information']}")
            if 'Note' in data:
                print(f"ğŸ“ APIé™åˆ¶æç¤º: {data['Note']}")
            
            if 'feed' not in data:
                print("âš ï¸ æœªæ‰¾åˆ°æ–°é—»æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                simulated_data = self._get_simulated_news()
                # ç¼“å­˜æ¨¡æ‹Ÿæ•°æ®ä»¥é¿å…é‡å¤APIè°ƒç”¨
                self.news_cache[cache_key] = (datetime.now(), simulated_data)
                return simulated_data
            
            processed_data = self._process_news(data['feed'])
            processed_data["success"] = True
            processed_data["api_calls_remaining"] = self.daily_limit - self.api_call_count
            
            # ç¼“å­˜ç»“æœ
            self.news_cache[cache_key] = (datetime.now(), processed_data)
            return processed_data
            
        except Exception as e:
            print(f"Alpha Vantageæ–°é—»è·å–å¤±è´¥: {str(e)}")
            simulated_data = self._get_simulated_news()
            self.news_cache[cache_key] = (datetime.now(), simulated_data)
            return simulated_data

    def _is_api_limit_reached(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°APIé™åˆ¶"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€å¤©
        if self.last_api_call_time and self.last_api_call_time.date() != datetime.now().date():
            # æ–°çš„ä¸€å¤©ï¼Œé‡ç½®è®¡æ•°å™¨
            self.api_call_count = 0
            print("ğŸ”„ æ–°çš„ä¸€å¤©ï¼Œé‡ç½®APIè°ƒç”¨è®¡æ•°å™¨")
            return False
        
        if self.api_call_count >= self.daily_limit:
            print(f"ğŸš« å·²è¾¾åˆ°æ¯æ—¥APIé™åˆ¶: {self.api_call_count}/{self.daily_limit}")
            return True
        
        return False

    def get_forex_specific_news(self, currency_pair: str = None, days_back: int = 1) -> Dict:
        """è·å–ç‰¹å®šè´§å¸å¯¹ç›¸å…³çš„å¤–æ±‡æ–°é—»"""
        try:
            if currency_pair and currency_pair in self.currency_to_tickers:
                tickers = ",".join(self.currency_to_tickers[currency_pair])
                result = self.get_news_sentiment(
                    topics=self.forex_topics,
                    tickers=tickers,
                    limit=20
                )
            else:
                result = self.get_news_sentiment(
                    topics=self.forex_topics,
                    limit=20
                )
            
            # ç¡®ä¿è¿”å›ç»“æœæœ‰ success å­—æ®µ
            if result and "success" not in result:
                result["success"] = True
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"è·å–å¤–æ±‡æ–°é—»å¤±è´¥: {str(e)}",
                "source": "economic_calendar"
            }

    def get_economic_events_schedule(self, days_ahead: int = 7, country: str = None) -> Dict:
        """è·å–ç»æµæ•°æ®å‘å¸ƒæ—¥ç¨‹"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"events_{days_ahead}_{country}"
            if cache_key in self.events_cache:
                cache_time, cached_data = self.events_cache[cache_key]
                if (datetime.now() - cache_time).seconds < self.cache_ttl:
                    print("ğŸ” ä½¿ç”¨ç¼“å­˜çš„äº‹ä»¶æ•°æ®")
                    return cached_data
            
            real_events = self._get_economic_calendar(days_ahead, country)
            if real_events:
                real_events["success"] = True
                self.events_cache[cache_key] = (datetime.now(), real_events)
                return real_events
            
            events = self._get_realistic_simulated_events(days_ahead, country)
            result = {
                "success": True,
                'timestamp': datetime.now().isoformat(),
                'timeframe': f'next_{days_ahead}_days',
                'country_filter': country,
                'total_events': len(events),
                'high_impact_events': len([e for e in events if e.get('importance') == 'high']),
                'events': events,
                'source': 'simulated_data'
            }
            
            self.events_cache[cache_key] = (datetime.now(), result)
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"è·å–ç»æµäº‹ä»¶æ—¥ç¨‹å¤±è´¥: {str(e)}",
                "source": "economic_calendar"
            }

    def get_comprehensive_economic_calendar(self, currency_pair: str = None, days_ahead: int = 3) -> Dict:
        """è·å–ç»¼åˆç»æµæ—¥å†ï¼ˆAlpha Vantageæ–°é—» + ç»æµæ•°æ®å‘å¸ƒï¼‰"""
        try:
            # éªŒè¯è¾“å…¥å‚æ•°
            if days_ahead < 1 or days_ahead > 7:
                return {
                    "success": False,
                    "error": "days_ahead å‚æ•°å¿…é¡»åœ¨ 1-7 èŒƒå›´å†…",
                    "source": "economic_calendar"
                }
                
            news_data = self.get_forex_specific_news(currency_pair)
            events_schedule = self.get_economic_events_schedule(days_ahead=days_ahead)
            
            # å¦‚æœæ–°é—»æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            if not news_data.get("success"):
                print("âš ï¸ æ–°é—»æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ–°é—»æ•°æ®")
                news_data = self._get_simulated_news()
            
            # å¦‚æœäº‹ä»¶æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            if not events_schedule.get("success"):
                print("âš ï¸ äº‹ä»¶æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿäº‹ä»¶æ•°æ®")
                events_schedule = {
                    "success": True,
                    'timestamp': datetime.now().isoformat(),
                    'timeframe': f'next_{days_ahead}_days',
                    'total_events': 3,
                    'high_impact_events': 1,
                    'events': self._get_realistic_simulated_events(days_ahead),
                    'source': 'simulated_data'
                }
            
            analysis_result = self.analyze_economic_calendar_with_openai(
                news_data, events_schedule, currency_pair
            )
            
            return {
                "success": True,
                'currency_pair': currency_pair,
                'timeframe': f'next_{days_ahead}_days',
                'news_summary': {
                    'total_articles': news_data.get('total_articles', 0),
                    'high_impact_news': news_data.get('high_impact_count', 0),
                    'overall_sentiment': news_data.get('overall_sentiment', {}),
                    'bullish_count': news_data.get('bullish_count', 0),
                    'bearish_count': news_data.get('bearish_count', 0),
                    'source': news_data.get('source', 'unknown')
                },
                'economic_events': {
                    'total_events': events_schedule.get('total_events', 0),
                    'high_impact_events': events_schedule.get('high_impact_events', 0),
                    'source': events_schedule.get('source', 'unknown')
                },
                'integrated_analysis': analysis_result,
                'key_events_timeline': self._extract_events_timeline(events_schedule),
                'market_sentiment_analysis': self._analyze_market_sentiment(news_data),
                'api_usage': {
                    'calls_made': self.api_call_count,
                    'calls_remaining': self.daily_limit - self.api_call_count,
                    'test_mode': self.test_mode
                },
                'source': 'economic_calendar'
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"è·å–ç»¼åˆç»æµæ—¥å†å¤±è´¥: {str(e)}",
                "source": "economic_calendar"
            }

    def health_check(self) -> Dict:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
            test_news = self.get_forex_specific_news("EUR/USD")
            test_events = self.get_economic_events_schedule(1)
            
            return {
                "success": True,
                "status": "healthy",
                "alpha_vantage_working": test_news.get("success", False) and not self.test_mode,
                "openai_working": self.openai_client is not None,
                "test_mode": self.test_mode,
                "api_usage": {
                    "calls_made": self.api_call_count,
                    "calls_remaining": self.daily_limit - self.api_call_count,
                    "daily_limit": self.daily_limit
                },
                "cache_status": {
                    "news_cache_size": len(self.news_cache),
                    "events_cache_size": len(self.events_cache)
                },
                "test_currency_pair": "EUR/USD",
                "news_articles_count": test_news.get('total_articles', 0) if test_news.get("success") else 0,
                "events_count": test_events.get('total_events', 0) if test_events.get("success") else 0
            }
            
        except Exception as e:
            return {
                "success": False,
                "status": "unhealthy",
                "error": str(e)
            }

    def get_calendar_config(self) -> Dict:
        """è·å–å½“å‰é…ç½®"""
        return {
            "success": True,
            "alpha_vantage_enabled": bool(self.alpha_vantage_key) and not self.test_mode,
            "openai_enabled": self.openai_client is not None,
            "test_mode": self.test_mode,
            "api_limits": {
                "daily_limit": self.daily_limit,
                "calls_made": self.api_call_count,
                "calls_remaining": self.daily_limit - self.api_call_count
            },
            "cache_settings": {
                "news_cache_ttl": self.cache_ttl,
                "news_cache_size": len(self.news_cache),
                "events_cache_size": len(self.events_cache)
            },
            "supported_currency_pairs": list(self.currency_to_tickers.keys()),
            "available_methods": [
                "get_forex_specific_news",
                "get_economic_events_schedule", 
                "get_comprehensive_economic_calendar",
                "health_check"
            ]
        }

    # å…¶ä»–è¾…åŠ©æ–¹æ³•ä¿æŒä¸å˜...
    def _process_news(self, news_feed: List) -> Dict:
        """å¤„ç†Alpha Vantageæ–°é—»æ•°æ®"""
        processed_articles = []
        
        for article in news_feed[:30]:
            try:
                title = article.get('title', '')
                summary = article.get('summary', '')
                published = article.get('time_published', '')
                source = article.get('source', 'Unknown')
                url = article.get('url', '')
                
                sentiment_info = article.get('overall_sentiment_score', 0)
                sentiment_label = article.get('overall_sentiment_label', 'neutral')
                relevance_score = article.get('relevance_score', '0')
                
                ticker_sentiment = article.get('ticker_sentiment', [])
                topics = [item['topic'] for item in article.get('topics', [])]
                
                related_currencies = self._extract_currencies_from_tickers(ticker_sentiment)
                event_type = self._identify_event_type(title + " " + summary)
                importance = self._assess_news_importance(sentiment_label, event_type, title, float(relevance_score))
                trading_impact = self._assess_trading_impact_from_sentiment(sentiment_label, importance, sentiment_info)
                
                processed_articles.append({
                    'title': title,
                    'summary': summary,
                    'published_at': published,
                    'source': source,
                    'url': url,
                    'sentiment_score': sentiment_info,
                    'sentiment_label': sentiment_label,
                    'relevance_score': relevance_score,
                    'related_tickers': [item['ticker'] for item in ticker_sentiment],
                    'ticker_sentiment': ticker_sentiment,
                    'topics': topics,
                    'event_type': event_type,
                    'affected_currency_pairs': related_currencies,
                    'importance': importance,
                    'trading_impact': trading_impact,
                    'volatility_expected': 'high' if importance == 'high' else 'medium',
                    'content_preview': summary[:150] + '...' if len(summary) > 150 else summary
                })
                
            except Exception as e:
                print(f"å¤„ç†æ–°é—»æ–‡ç« æ—¶å‡ºé”™: {e}")
                continue
        
        overall_sentiment = self._calculate_overall_sentiment(processed_articles)
        
        return {
            'timestamp': datetime.now().isoformat(),
            'total_articles': len(processed_articles),
            'articles': processed_articles,
            'overall_sentiment': overall_sentiment,
            'high_impact_count': len([a for a in processed_articles if a['importance'] == 'high']),
            'bullish_count': len([a for a in processed_articles if a['sentiment_label'] == 'bullish']),
            'bearish_count': len([a for a in processed_articles if a['sentiment_label'] == 'bearish']),
            'source': 'Alpha Vantage'
        }

    def _extract_currencies_from_tickers(self, ticker_sentiment: List) -> List[str]:
        """ä»è‚¡ç¥¨ä»£ç ä¸­æå–ç›¸å…³è´§å¸å¯¹"""
        currencies = set()
        
        for item in ticker_sentiment:
            ticker = item.get('ticker', '')
            if ticker in ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD', 'USDCAD', 'NZDUSD']:
                currencies.add(ticker)
            elif ticker in ['EUR', 'USD', 'GBP', 'JPY', 'CHF', 'AUD', 'CAD', 'NZD']:
                for pair in self.currency_to_tickers.keys():
                    if ticker in pair:
                        currencies.add(pair)
        
        return list(currencies) if currencies else ['Multiple pairs']

    def _calculate_overall_sentiment(self, articles: List) -> Dict:
        """è®¡ç®—æ•´ä½“å¸‚åœºæƒ…ç»ª"""
        if not articles:
            return {'score': 0, 'label': 'neutral', 'strength': 'weak'}
        
        scores = [a['sentiment_score'] for a in articles if a.get('sentiment_score') is not None]
        if not scores:
            return {'score': 0, 'label': 'neutral', 'strength': 'weak'}
        
        avg_score = sum(scores) / len(scores)
        
        if avg_score >= 0.35:
            label = 'bullish'
            strength = 'strong' if avg_score >= 0.6 else 'moderate'
        elif avg_score <= -0.35:
            label = 'bearish'
            strength = 'strong' if avg_score <= -0.6 else 'moderate'
        else:
            label = 'neutral'
            strength = 'weak'
        
        return {
            'score': round(avg_score, 3),
            'label': label,
            'strength': strength,
            'description': f"æ•´ä½“å¸‚åœºæƒ…ç»ª{label}ï¼Œå¼ºåº¦{strength}"
        }

    def _assess_news_importance(self, sentiment_label: str, event_type: str, title: str, relevance_score: float) -> str:
        """è¯„ä¼°æ–°é—»é‡è¦æ€§"""
        high_impact_keywords = [
            'rate decision', 'interest rate', 'nonfarm payrolls', 'nfp', 
            'cpi', 'inflation', 'gdp', 'federal reserve', 'ecb', 'boe', 'boj'
        ]
        
        title_lower = title.lower()
        score = 0
        
        if sentiment_label in ['bullish', 'bearish']:
            score += 2
        
        if event_type in ['central_bank_decision', 'inflation_data', 'employment_data']:
            score += 2
        
        if any(keyword in title_lower for keyword in high_impact_keywords):
            score += 2
        
        score += relevance_score
        
        if score >= 4:
            return 'high'
        elif score >= 2:
            return 'medium'
        else:
            return 'low'

    def _assess_trading_impact_from_sentiment(self, sentiment_label: str, importance: str, sentiment_score: float) -> str:
        """åŸºäºæƒ…ç»ªè¯„ä¼°äº¤æ˜“å½±å“"""
        sentiment_strength = "å¼ºçƒˆ" if abs(sentiment_score) >= 0.5 else "æ¸©å’Œ"
        
        if importance == 'high':
            if sentiment_label == 'bearish':
                return f'é«˜è´Ÿé¢å½±å“é¢„æœŸï¼Œ{sentiment_strength}çœ‹è·Œæƒ…ç»ªï¼Œå»ºè®®é¿é™©å¤´å¯¸'
            elif sentiment_label == 'bullish':
                return f'é«˜æ­£é¢å½±å“é¢„æœŸï¼Œ{sentiment_strength}çœ‹æ¶¨æƒ…ç»ªï¼Œå»ºè®®é£é™©å¤´å¯¸'
            else:
                return f'é«˜å½±å“äº‹ä»¶ï¼Œ{sentiment_strength}ä¸­æ€§æƒ…ç»ªï¼Œå¯†åˆ‡ç›‘æ§'
        elif importance == 'medium':
            return 'ä¸­ç­‰å½±å“ï¼Œè°¨æ…äº¤æ˜“ï¼Œæ³¨æ„é£é™©ç®¡ç†'
        else:
            return 'ä½å½±å“ï¼Œæ­£å¸¸äº¤æ˜“ç¯å¢ƒ'

    def _get_simulated_news(self) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ•°æ®ä½œä¸ºå›é€€"""
        simulated_articles = [
            {
                'title': 'Federal Reserve Maintains Interest Rates Amid Stable Inflation',
                'summary': 'The Federal Reserve kept interest rates unchanged as inflation remains within target range.',
                'published_at': datetime.now().isoformat(),
                'source': 'Simulated Data',
                'url': '',
                'sentiment_score': 0.1,
                'sentiment_label': 'neutral',
                'relevance_score': '0.8',
                'related_tickers': ['USD', 'EUR'],
                'ticker_sentiment': [],
                'topics': ['central_banks', 'monetary_policy'],
                'event_type': 'central_bank_decision',
                'affected_currency_pairs': ['EUR/USD', 'GBP/USD', 'USD/JPY'],
                'importance': 'high',
                'trading_impact': 'é«˜å½±å“äº‹ä»¶ï¼Œå¯†åˆ‡å…³æ³¨ç¾è”å‚¨æ”¿ç­–',
                'volatility_expected': 'high',
                'content_preview': 'ç¾è”å‚¨ç»´æŒåˆ©ç‡ä¸å˜...'
            }
        ]
        
        return {
            "success": True,
            'timestamp': datetime.now().isoformat(),
            'total_articles': len(simulated_articles),
            'articles': simulated_articles,
            'overall_sentiment': {'score': 0.18, 'label': 'neutral', 'strength': 'weak'},
            'high_impact_count': 1,
            'bullish_count': 1,
            'bearish_count': 0,
            'source': 'simulated_data'
        }

    def _identify_event_type(self, content: str) -> str:
        """è¯†åˆ«äº‹ä»¶ç±»å‹"""
        content_lower = content.lower()
        
        for event_type, keywords in self.event_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                return event_type
        
        return 'other'

    def _get_economic_calendar(self, days_ahead: int, country: str = None) -> Optional[Dict]:
        """
        ä½¿ç”¨æ–°é—»æƒ…æ„Ÿæ•°æ®æ¥æ¨¡æ‹Ÿç»æµæ—¥å†
        """
        if not self.alpha_vantage_key or self.test_mode:
            print("âš ï¸ Alpha Vantage APIå¯†é’¥æœªé…ç½®æˆ–æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return None
        
        try:
            # ä½¿ç”¨ NEWS_SENTIMENT è€Œä¸æ˜¯ ECONOMIC_CALENDAR
            params = {
                'function': 'NEWS_SENTIMENT',
                'apikey': self.alpha_vantage_key,
                'topics': 'economy_monetary,economy_fiscal,economy_macro,financial_markets',
                'sort': 'LATEST',
                'limit': 20
            }
            
            # æ ¹æ®å›½å®¶è¿‡æ»¤ç›¸å…³ä¸»é¢˜
            country_topics = {
                'us': 'federal reserve,interest rates,us economy',
                'eu': 'ecb,european central bank,eurozone',
                'uk': 'bank of england,uk economy,brexit',
                'jp': 'bank of japan,japan economy'
            }
            
            if country and country in country_topics:
                print(f"ğŸ” è·å– {country} ç›¸å…³ç»æµæ–°é—»")
            
            print(f"ğŸ” å‘é€æ–°é—»æƒ…æ„ŸAPIè¯·æ±‚: {params}")
            
            response = requests.get(self.alpha_vantage_base_url, params=params, timeout=15)
            response.raise_for_status()
            
            data = response.json()
            
            print(f"ğŸ“Š Alpha Vantage æ–°é—»å“åº”é”®: {list(data.keys())}")
            
            # æ£€æŸ¥APIé™åˆ¶æˆ–é”™è¯¯ä¿¡æ¯
            if 'Information' in data:
                print(f"â„¹ï¸ APIä¿¡æ¯: {data['Information']}")
                return None
            if 'Note' in data:
                print(f"ğŸ“ APIé™åˆ¶æç¤º: {data['Note']}")
                return None
            if 'Error Message' in data:
                print(f"âŒ APIé”™è¯¯: {data['Error Message']}")
                return None
            
            if 'feed' in data:
                # å¤„ç†æ–°é—»æ•°æ®ä½œä¸ºç»æµäº‹ä»¶
                events = self._convert_news_to_economic_events(data['feed'], days_ahead)
                print(f"âœ… æˆåŠŸè·å– {len(events)} ä¸ªç»æµç›¸å…³äº‹ä»¶")
                return {
                    'events': events,
                    'source': 'alpha_vantage_news'
                }
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°æ–°é—»æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return None
            
        except requests.exceptions.Timeout:
            print(f"âŒ Alpha Vantage è¯·æ±‚è¶…æ—¶")
            return None
        except requests.exceptions.RequestException as e:
            print(f"âŒ Alpha Vantage ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"âŒ Alpha Vantage æ–°é—»è·å–å¤±è´¥: {e}")
            return None

    def _convert_news_to_economic_events(self, news_feed: List, days_ahead: int) -> List[Dict]:
        """å°†æ–°é—»æ•°æ®è½¬æ¢ä¸ºç»æµäº‹ä»¶æ ¼å¼"""
        events = []
        today = datetime.now()
        
        for article in news_feed[:10]:  # åªå¤„ç†å‰10ç¯‡æ–‡ç« 
            try:
                title = article.get('title', '')
                summary = article.get('summary', '')
                published = article.get('time_published', '')
                source = article.get('source', 'Unknown')
                
                # è¯†åˆ«äº‹ä»¶ç±»å‹å’Œé‡è¦æ€§ - ä¿®å¤å‚æ•°é¡ºåº
                event_type = self._identify_event_type(title + " " + summary)
                sentiment_label = article.get('overall_sentiment_label', 'neutral')
                relevance_score = float(article.get('relevance_score', 0))
                
                importance = self._assess_news_importance(
                    sentiment_label,      # ç¬¬ä¸€ä¸ªå‚æ•°
                    event_type,           # ç¬¬äºŒä¸ªå‚æ•°  
                    title,                # ç¬¬ä¸‰ä¸ªå‚æ•°
                    relevance_score       # ç¬¬å››ä¸ªå‚æ•°
                )
                
                # æå–ç›¸å…³è´§å¸å¯¹
                ticker_sentiment = article.get('ticker_sentiment', [])
                related_currencies = self._extract_currencies_from_tickers(ticker_sentiment)
                
                # è§£æå‘å¸ƒæ—¶é—´
                event_date = today
                if published:
                    try:
                        # å°è¯•è§£æ Alpha Vantage çš„æ—¶é—´æ ¼å¼: 20241020T000000
                        if 'T' in published:
                            date_part = published.split('T')[0]
                            event_date = datetime.strptime(date_part, '%Y%m%d')
                    except:
                        pass
                
                events.append({
                    'event_name': title[:100],  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                    'country': self._infer_country_from_content(title + " " + summary),
                    'date': event_date.strftime('%Y-%m-%d'),
                    'time': event_date.strftime('%H:%M'),
                    'importance': importance,
                    'currency_impact': related_currencies if related_currencies else ['Multiple'],
                    'previous_value': 'N/A',
                    'forecast': 'N/A', 
                    'actual': 'N/A',
                    'source': source,
                    'description': summary[:200] + '...' if len(summary) > 200 else summary,
                    'event_type': event_type
                })
                
            except Exception as e:
                print(f"å¤„ç†æ–°é—»æ–‡ç« æ—¶å‡ºé”™: {e}")
                continue
        
        return events

    def _infer_country_from_content(self, content: str) -> str:
        """ä»å†…å®¹æ¨æ–­å›½å®¶"""
        content_lower = content.lower()
        
        country_keywords = {
            'us': ['federal reserve', 'fed', 'us ', 'united states', 'dollar', 'wall street'],
            'eu': ['ecb', 'european central bank', 'eurozone', 'euro ', 'brussels'],
            'uk': ['bank of england', 'boe', 'uk ', 'united kingdom', 'pound', 'brexit'],
            'jp': ['bank of japan', 'boj', 'japan', 'yen', 'tokyo']
        }
        
        for country, keywords in country_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                return country.upper()
        
        return 'GLOBAL'

    def _get_realistic_simulated_events(self, days_ahead: int, country: str = None) -> List[Dict]:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿç»æµäº‹ä»¶æ•°æ®
        """
        events = []
        today = datetime.now()
        
        for i in range(days_ahead):
            event_date = today + timedelta(days=i)
            
            # éå†æ‰€æœ‰å›½å®¶çš„äº‹ä»¶æ¨¡æ¿
            for country_code, country_events in self.economic_events.items():
                # æŒ‰å›½å®¶è¿‡æ»¤
                if country and country_code != country:
                    continue
                    
                for event_template in country_events:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å…¸å‹å‘å¸ƒæ—¥ï¼ˆç®€åŒ–é€»è¾‘ï¼‰
                    if event_date.day == event_template['typical_day']:
                        events.append({
                            'event_name': event_template['name'],
                            'country': country_code.upper(),
                            'date': event_date.strftime('%Y-%m-%d'),
                            'time': event_template['typical_time'],
                            'importance': event_template['importance'],
                            'currency_impact': event_template['currency_impact'],
                            'previous_value': 'å¾…å‘å¸ƒ',
                            'forecast': 'å¾…å‘å¸ƒ',
                            'actual': 'å¾…å‘å¸ƒ',
                            'source': event_template['source']
                        })
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°äº‹ä»¶ï¼Œæ·»åŠ ä¸€äº›é»˜è®¤äº‹ä»¶
        if not events:
            default_events = [
                {
                    'event_name': 'US Federal Reserve Meeting',
                    'country': 'US',
                    'date': (today + timedelta(days=1)).strftime('%Y-%m-%d'),
                    'time': '14:00 EST',
                    'importance': 'high',
                    'currency_impact': ['USD', 'All majors'],
                    'previous_value': '5.50%',
                    'forecast': '5.50%',
                    'actual': 'å¾…å‘å¸ƒ',
                    'source': 'Federal Reserve'
                },
                {
                    'event_name': 'Eurozone CPI',
                    'country': 'EU',
                    'date': (today + timedelta(days=2)).strftime('%Y-%m-%d'),
                    'time': '10:00 GMT',
                    'importance': 'high',
                    'currency_impact': ['EUR', 'EUR/USD'],
                    'previous_value': '2.4%',
                    'forecast': '2.3%',
                    'actual': 'å¾…å‘å¸ƒ',
                    'source': 'Eurostat'
                }
            ]
            events.extend(default_events)
        
        return events

    # å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜...
    def analyze_economic_calendar_with_openai(self, news_data: Dict, events_data: Dict, currency_pair: str = None) -> Dict:
        """ä½¿ç”¨OpenAIæ·±åº¦åˆ†æç»æµæ—¥å†"""
        if not self.openai_client:
            return self._get_simplified_analysis(news_data, events_data, currency_pair)
        
        try:
            # éªŒè¯è¾“å…¥æ•°æ®
            if not news_data or not events_data:
                return {
                    "success": False,
                    "error": "è¾“å…¥æ•°æ®ä¸ºç©º",
                    "source": "economic_calendar"
                }
            
            # ç¡®ä¿æ•°æ®æ˜¯å­—å…¸æ ¼å¼
            if isinstance(news_data, str):
                try:
                    import json
                    news_data = json.loads(news_data)
                except:
                    return {
                        "success": False,
                        "error": "æ–°é—»æ•°æ®æ ¼å¼é”™è¯¯",
                        "source": "economic_calendar"
                    }
            
            if isinstance(events_data, str):
                try:
                    import json
                    events_data = json.loads(events_data)
                except:
                    return {
                        "success": False,
                        "error": "äº‹ä»¶æ•°æ®æ ¼å¼é”™è¯¯",
                        "source": "economic_calendar"
                    }
            
            prompt = self._build_enhanced_economic_calendar_prompt(news_data, events_data, currency_pair)
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å¤–æ±‡äº¤æ˜“ç­–ç•¥å¸ˆå’Œé£é™©ç®¡ç†ä¸“å®¶ã€‚åŸºäºæä¾›çš„å¸‚åœºæ–°é—»ã€æƒ…ç»ªæ•°æ®å’Œç»æµäº‹ä»¶æ—¥ç¨‹ï¼Œæä¾›ä¸“ä¸šçš„äº¤æ˜“åˆ†æå’Œå…·ä½“çš„é£é™©ç®¡ç†å»ºè®®ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            return {
                "success": True,
                'currency_pair': currency_pair,
                'analysis': analysis_text,
                'key_events_timeline': self._extract_events_timeline(events_data),
                'risk_assessment': self._assess_calendar_risk(news_data, events_data),
                'sentiment_analysis': news_data.get('overall_sentiment', {}),
                'status': 'openai_analysis'
            }
            
        except Exception as e:
            print(f"âŒ OpenAIæ·±åº¦åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": f"AIåˆ†æå¤±è´¥: {str(e)}",
                "source": "economic_calendar"
            }

    def _build_enhanced_economic_calendar_prompt(self, news_data: Dict, events_data: Dict, currency_pair: str) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        prompt_parts = []
        
        prompt_parts.append(f"è¯·åˆ†æä»¥ä¸‹å¤–æ±‡å¸‚åœºä¿¡æ¯ï¼Œé‡ç‚¹å…³æ³¨{currency_pair if currency_pair else 'ä¸»è¦è´§å¸å¯¹'}çš„äº¤æ˜“æœºä¼šï¼š")
        prompt_parts.append("")
        
        # æ–°é—»æ•°æ®éƒ¨åˆ†
        if news_data.get('success'):
            prompt_parts.append("=== å¸‚åœºæ–°é—»å’Œæƒ…ç»ªåˆ†æ ===")
            prompt_parts.append(f"æ€»æ–‡ç« æ•°: {news_data.get('total_articles', 0)}")
            prompt_parts.append(f"é«˜å½±å“æ–°é—»: {news_data.get('high_impact_count', 0)}")
            
            sentiment = news_data.get('overall_sentiment', {})
            prompt_parts.append(f"æ•´ä½“æƒ…ç»ª: {sentiment.get('label', 'neutral')} (å¼ºåº¦: {sentiment.get('strength', 'weak')})")
            prompt_parts.append(f"çœ‹æ¶¨æ–‡ç« : {news_data.get('bullish_count', 0)}")
            prompt_parts.append(f"çœ‹è·Œæ–‡ç« : {news_data.get('bearish_count', 0)}")
            
            # æ·»åŠ é‡è¦æ–°é—»æ ‡é¢˜
            important_articles = [article for article in news_data.get('articles', []) 
                                if article.get('importance') == 'high']
            if important_articles:
                prompt_parts.append("é‡è¦æ–°é—»æ ‡é¢˜:")
                for article in important_articles[:3]:
                    prompt_parts.append(f"- {article.get('title', '')}")
        else:
            prompt_parts.append("æ–°é—»æ•°æ®è·å–å¤±è´¥")
        
        prompt_parts.append("")
        
        # ç»æµäº‹ä»¶éƒ¨åˆ†
        if events_data.get('success'):
            prompt_parts.append("=== ç»æµäº‹ä»¶æ—¥ç¨‹ ===")
            prompt_parts.append(f"æ€»äº‹ä»¶æ•°: {events_data.get('total_events', 0)}")
            prompt_parts.append(f"é«˜å½±å“äº‹ä»¶: {events_data.get('high_impact_events', 0)}")
            
            high_impact_events = [event for event in events_data.get('events', []) 
                                if event.get('importance') == 'high']
            if high_impact_events:
                prompt_parts.append("é«˜å½±å“äº‹ä»¶:")
                for event in high_impact_events[:5]:
                    prompt_parts.append(f"- {event.get('event_name', '')} ({event.get('date', '')} {event.get('time', '')})")
        
        prompt_parts.append("")
        prompt_parts.append("è¯·åŸºäºä»¥ä¸Šä¿¡æ¯æä¾›ï¼š")
        prompt_parts.append("1. å¸‚åœºæƒ…ç»ªåˆ†æå’Œè¶‹åŠ¿åˆ¤æ–­")
        prompt_parts.append("2. é‡è¦ç»æµäº‹ä»¶å¯¹æ±‡ç‡çš„å½±å“é¢„æµ‹")
        prompt_parts.append("3. å…·ä½“çš„äº¤æ˜“å»ºè®®å’Œé£é™©ç®¡ç†ç­–ç•¥")
        prompt_parts.append("4. éœ€è¦é‡ç‚¹å…³æ³¨çš„é£é™©å› ç´ ")
        
        return "\n".join(prompt_parts)

    def _extract_events_timeline(self, events_data: Dict) -> List[Dict]:
        """æå–äº‹ä»¶æ—¶é—´çº¿"""
        timeline = []
        
        if events_data.get('success'):
            events = events_data.get('events', [])
            for event in events:
                timeline.append({
                    'event': event.get('event_name', ''),
                    'date': event.get('date', ''),
                    'time': event.get('time', ''),
                    'importance': event.get('importance', 'medium'),
                    'currency_impact': event.get('currency_impact', [])
                })
        
        return timeline

    def _analyze_market_sentiment(self, news_data: Dict) -> Dict:
        """åˆ†æå¸‚åœºæƒ…ç»ª"""
        if not news_data.get('success'):
            return {'overall': 'unknown', 'confidence': 0}
        
        sentiment = news_data.get('overall_sentiment', {})
        bullish_count = news_data.get('bullish_count', 0)
        bearish_count = news_data.get('bearish_count', 0)
        total_articles = news_data.get('total_articles', 1)
        
        bullish_ratio = bullish_count / total_articles
        bearish_ratio = bearish_count / total_articles
        
        if bullish_ratio > 0.6:
            market_sentiment = 'strongly_bullish'
        elif bullish_ratio > 0.4:
            market_sentiment = 'bullish'
        elif bearish_ratio > 0.6:
            market_sentiment = 'strongly_bearish'
        elif bearish_ratio > 0.4:
            market_sentiment = 'bearish'
        else:
            market_sentiment = 'neutral'
        
        return {
            'overall': market_sentiment,
            'confidence': max(bullish_ratio, bearish_ratio),
            'bullish_articles': bullish_count,
            'bearish_articles': bearish_count,
            'sentiment_score': sentiment.get('score', 0)
        }

    def _get_simplified_analysis(self, news_data: Dict, events_data: Dict, currency_pair: str) -> Dict:
        """ç®€åŒ–åˆ†æï¼ˆå½“OpenAIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        sentiment_analysis = self._analyze_market_sentiment(news_data)
        
        # åŸºäºæ–°é—»æƒ…ç»ªå’Œäº‹ä»¶æ•°é‡ç”Ÿæˆç®€å•åˆ†æ
        if sentiment_analysis['overall'] == 'strongly_bullish':
            recommendation = "å¼ºçƒˆçœ‹æ¶¨"
        elif sentiment_analysis['overall'] == 'bullish':
            recommendation = "çœ‹æ¶¨"
        elif sentiment_analysis['overall'] == 'strongly_bearish':
            recommendation = "å¼ºçƒˆçœ‹è·Œ"
        elif sentiment_analysis['overall'] == 'bearish':
            recommendation = "çœ‹è·Œ"
        else:
            recommendation = "ä¸­æ€§"
        
        high_impact_events = events_data.get('high_impact_events', 0)
        if high_impact_events > 0:
            recommendation += f"ï¼Œæ³¨æ„{high_impact_events}ä¸ªé«˜å½±å“äº‹ä»¶"
        
        return {
            'currency_pair': currency_pair,
            'analysis': f"åŸºäºå¸‚åœºæƒ…ç»ªåˆ†æï¼Œå½“å‰å»ºè®®ï¼š{recommendation}ã€‚å¸‚åœºæƒ…ç»ªï¼š{sentiment_analysis['overall']}ï¼Œç½®ä¿¡åº¦ï¼š{sentiment_analysis['confidence']:.2f}",
            'recommendation': recommendation,
            'confidence': sentiment_analysis['confidence'],
            'status': 'simplified_analysis'
        }

    def _assess_calendar_risk(self, news_data: Dict, events_data: Dict) -> Dict:
        """è¯„ä¼°æ—¥å†é£é™©"""
        risk_level = 'low'
        reasons = []
        
        # åŸºäºé«˜å½±å“æ–°é—»æ•°é‡è¯„ä¼°é£é™©
        high_impact_news = news_data.get('high_impact_count', 0)
        if high_impact_news >= 3:
            risk_level = 'high'
            reasons.append(f"é«˜å½±å“æ–°é—»æ•°é‡è¾ƒå¤š: {high_impact_news}")
        elif high_impact_news >= 1:
            risk_level = 'medium'
            reasons.append(f"å­˜åœ¨é«˜å½±å“æ–°é—»: {high_impact_news}")
        
        # åŸºäºé«˜å½±å“äº‹ä»¶æ•°é‡è¯„ä¼°é£é™©
        high_impact_events = events_data.get('high_impact_events', 0)
        if high_impact_events >= 2:
            risk_level = 'high'
            reasons.append(f"é«˜å½±å“äº‹ä»¶æ•°é‡è¾ƒå¤š: {high_impact_events}")
        elif high_impact_events >= 1 and risk_level != 'high':
            risk_level = 'medium'
            reasons.append(f"å­˜åœ¨é«˜å½±å“äº‹ä»¶: {high_impact_events}")
        
        return {
            'risk_level': risk_level,
            'reasons': reasons,
            'high_impact_news_count': high_impact_news,
            'high_impact_events_count': high_impact_events
        }